{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "##### Title: Exercice 5.2\n",
    "##### Author: Jerock Kalala\n",
    "##### Date: January 27th 2023\n",
    "##### Modified By: --\n",
    "##### Using Natural Language Processing (NLP)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Using the file, twitter_sample.csv file, which can be found in the \"data\" directory in the Week 5 GitHub repository:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "data": {
      "text/plain": "                Tweet Id                                          Tweet URL  \\\n0  \"1167429261210218497\"  https://twitter.com/animalhealthEU/status/1167...   \n1  \"1167375334670557185\"  https://twitter.com/PennyBrohnUK/status/116737...   \n2  \"1167237977615097861\"  https://twitter.com/lordbyronaf/status/1167237...   \n3  \"1167236897078480898\"  https://twitter.com/CountessDavis/status/11672...   \n4  \"1167228378191204353\"  https://twitter.com/Local12/status/11672283781...   \n\n  Tweet Posted Time (UTC)                                      Tweet Content  \\\n0    30 Aug 2019 13:30:00  Pets change our lives &amp; become a part of o...   \n1    30 Aug 2019 09:55:43  Another spot of our #morethanmedicine bus in #...   \n2    30 Aug 2019 00:49:54  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n3    30 Aug 2019 00:45:37  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n4    30 Aug 2019 00:11:46  What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...   \n\n  Tweet Type                Client  Retweets Received  Likes Received  \\\n0      Tweet  Twitter Ads Composer                  0               4   \n1      Tweet       Twitter Web App                  0               5   \n2    ReTweet   Twitter for Android                  0               0   \n3    ReTweet   Twitter for Android                  0               0   \n4    ReTweet             TweetDeck                  0               0   \n\n   Tweet Location Tweet Language  ...                 Name        Username  \\\n0        Brussels        English  ...   AnimalhealthEurope  animalhealthEU   \n1   Pill, Bristol        English  ...       Penny Brohn UK    PennyBrohnUK   \n2       Ohio, USA        English  ...         Lord ByronAF     lordbyronaf   \n3             NaN        English  ...  Lisa Countess davis   CountessDavis   \n4  Cincinnati, OH        English  ...     Local 12/WKRC-TV         Local12   \n\n                                            User Bio Verified or Non-Verified  \\\n0  AnimalhealthEurope represents manufacturers of...             Non-Verified   \n1  We help people live well with the impact of ca...             Non-Verified   \n2  It's easier to be who you are, than it is to b...             Non-Verified   \n3  I am named after @ElvisPresley daughter Lisa M...             Non-Verified   \n4  Local 12 is #Cincinnati's trusted source for b...                 Verified   \n\n                          Profile URL Protected or Non-protected  \\\n0  https://twitter.com/animalhealthEU              Non-Protected   \n1    https://twitter.com/PennyBrohnUK              Non-Protected   \n2     https://twitter.com/lordbyronaf              Non-Protected   \n3   https://twitter.com/CountessDavis              Non-Protected   \n4         https://twitter.com/Local12              Non-Protected   \n\n  User Followers  User Following  User Account Creation Date Impressions  \n0           3697             542        17 Dec 2012 09:14:15        7394  \n1           3227            1571        15 Sep 2010 09:44:02        6454  \n2           7808            8617        25 Jul 2012 15:43:47           0  \n3            291              81        26 Jan 2017 18:21:42           0  \n4         198675             651        02 Sep 2008 20:09:44           0  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet Id</th>\n      <th>Tweet URL</th>\n      <th>Tweet Posted Time (UTC)</th>\n      <th>Tweet Content</th>\n      <th>Tweet Type</th>\n      <th>Client</th>\n      <th>Retweets Received</th>\n      <th>Likes Received</th>\n      <th>Tweet Location</th>\n      <th>Tweet Language</th>\n      <th>...</th>\n      <th>Name</th>\n      <th>Username</th>\n      <th>User Bio</th>\n      <th>Verified or Non-Verified</th>\n      <th>Profile URL</th>\n      <th>Protected or Non-protected</th>\n      <th>User Followers</th>\n      <th>User Following</th>\n      <th>User Account Creation Date</th>\n      <th>Impressions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"1167429261210218497\"</td>\n      <td>https://twitter.com/animalhealthEU/status/1167...</td>\n      <td>30 Aug 2019 13:30:00</td>\n      <td>Pets change our lives &amp;amp; become a part of o...</td>\n      <td>Tweet</td>\n      <td>Twitter Ads Composer</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Brussels</td>\n      <td>English</td>\n      <td>...</td>\n      <td>AnimalhealthEurope</td>\n      <td>animalhealthEU</td>\n      <td>AnimalhealthEurope represents manufacturers of...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/animalhealthEU</td>\n      <td>Non-Protected</td>\n      <td>3697</td>\n      <td>542</td>\n      <td>17 Dec 2012 09:14:15</td>\n      <td>7394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"1167375334670557185\"</td>\n      <td>https://twitter.com/PennyBrohnUK/status/116737...</td>\n      <td>30 Aug 2019 09:55:43</td>\n      <td>Another spot of our #morethanmedicine bus in #...</td>\n      <td>Tweet</td>\n      <td>Twitter Web App</td>\n      <td>0</td>\n      <td>5</td>\n      <td>Pill, Bristol</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Penny Brohn UK</td>\n      <td>PennyBrohnUK</td>\n      <td>We help people live well with the impact of ca...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/PennyBrohnUK</td>\n      <td>Non-Protected</td>\n      <td>3227</td>\n      <td>1571</td>\n      <td>15 Sep 2010 09:44:02</td>\n      <td>6454</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"1167237977615097861\"</td>\n      <td>https://twitter.com/lordbyronaf/status/1167237...</td>\n      <td>30 Aug 2019 00:49:54</td>\n      <td>What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...</td>\n      <td>ReTweet</td>\n      <td>Twitter for Android</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Ohio, USA</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Lord ByronAF</td>\n      <td>lordbyronaf</td>\n      <td>It's easier to be who you are, than it is to b...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/lordbyronaf</td>\n      <td>Non-Protected</td>\n      <td>7808</td>\n      <td>8617</td>\n      <td>25 Jul 2012 15:43:47</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"1167236897078480898\"</td>\n      <td>https://twitter.com/CountessDavis/status/11672...</td>\n      <td>30 Aug 2019 00:45:37</td>\n      <td>What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...</td>\n      <td>ReTweet</td>\n      <td>Twitter for Android</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Lisa Countess davis</td>\n      <td>CountessDavis</td>\n      <td>I am named after @ElvisPresley daughter Lisa M...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/CountessDavis</td>\n      <td>Non-Protected</td>\n      <td>291</td>\n      <td>81</td>\n      <td>26 Jan 2017 18:21:42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"1167228378191204353\"</td>\n      <td>https://twitter.com/Local12/status/11672283781...</td>\n      <td>30 Aug 2019 00:11:46</td>\n      <td>What a great team ⁦@HealthSourceOH⁩ ⁦@Local12⁩...</td>\n      <td>ReTweet</td>\n      <td>TweetDeck</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Cincinnati, OH</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Local 12/WKRC-TV</td>\n      <td>Local12</td>\n      <td>Local 12 is #Cincinnati's trusted source for b...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/Local12</td>\n      <td>Non-Protected</td>\n      <td>198675</td>\n      <td>651</td>\n      <td>02 Sep 2008 20:09:44</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from datetime import date\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "corpus = pd.read_csv(\"E:\\\\Bellevue\\\\Winter_2022\\\\DSC 360 Data Mining Text Analytics an\\Week_5\\\\twitter_sample.csv\")\n",
    "corpus[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('English')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lowercase and remove special characters\\whitespace\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    #tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    doc = re.sub('\\n',' ',doc)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)\n",
    "\n",
    "def clean_tweets(doc):\n",
    "    doc = doc.str.replace('[^\\w\\s]', '', regex=True)\n",
    "    doc = doc.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "    return doc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Clean the “Tweet Content” column by removing non-text data and stop words."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "                Tweet Id                                          Tweet URL  \\\n0  \"1167429261210218497\"  https://twitter.com/animalhealthEU/status/1167...   \n1  \"1167375334670557185\"  https://twitter.com/PennyBrohnUK/status/116737...   \n2  \"1167237977615097861\"  https://twitter.com/lordbyronaf/status/1167237...   \n3  \"1167236897078480898\"  https://twitter.com/CountessDavis/status/11672...   \n4  \"1167228378191204353\"  https://twitter.com/Local12/status/11672283781...   \n\n  Tweet Posted Time (UTC)                                      Tweet Content  \\\n0    30 Aug 2019 13:30:00  pets change lives amp become part families tha...   \n1    30 Aug 2019 09:55:43  another spot morethanmedicine bus bristol week...   \n2    30 Aug 2019 00:49:54  great team healthsourceoh local morethanmedici...   \n3    30 Aug 2019 00:45:37  great team healthsourceoh local morethanmedici...   \n4    30 Aug 2019 00:11:46  great team healthsourceoh local morethanmedici...   \n\n  Tweet Type                Client  Retweets Received  Likes Received  \\\n0      Tweet  Twitter Ads Composer                  0               4   \n1      Tweet       Twitter Web App                  0               5   \n2    ReTweet   Twitter for Android                  0               0   \n3    ReTweet   Twitter for Android                  0               0   \n4    ReTweet             TweetDeck                  0               0   \n\n   Tweet Location Tweet Language  ...                 Name        Username  \\\n0        Brussels        English  ...   AnimalhealthEurope  animalhealthEU   \n1   Pill, Bristol        English  ...       Penny Brohn UK    PennyBrohnUK   \n2       Ohio, USA        English  ...         Lord ByronAF     lordbyronaf   \n3             NaN        English  ...  Lisa Countess davis   CountessDavis   \n4  Cincinnati, OH        English  ...     Local 12/WKRC-TV         Local12   \n\n                                            User Bio Verified or Non-Verified  \\\n0  AnimalhealthEurope represents manufacturers of...             Non-Verified   \n1  We help people live well with the impact of ca...             Non-Verified   \n2  It's easier to be who you are, than it is to b...             Non-Verified   \n3  I am named after @ElvisPresley daughter Lisa M...             Non-Verified   \n4  Local 12 is #Cincinnati's trusted source for b...                 Verified   \n\n                          Profile URL Protected or Non-protected  \\\n0  https://twitter.com/animalhealthEU              Non-Protected   \n1    https://twitter.com/PennyBrohnUK              Non-Protected   \n2     https://twitter.com/lordbyronaf              Non-Protected   \n3   https://twitter.com/CountessDavis              Non-Protected   \n4         https://twitter.com/Local12              Non-Protected   \n\n  User Followers  User Following  User Account Creation Date Impressions  \n0           3697             542        17 Dec 2012 09:14:15        7394  \n1           3227            1571        15 Sep 2010 09:44:02        6454  \n2           7808            8617        25 Jul 2012 15:43:47           0  \n3            291              81        26 Jan 2017 18:21:42           0  \n4         198675             651        02 Sep 2008 20:09:44           0  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Tweet Id</th>\n      <th>Tweet URL</th>\n      <th>Tweet Posted Time (UTC)</th>\n      <th>Tweet Content</th>\n      <th>Tweet Type</th>\n      <th>Client</th>\n      <th>Retweets Received</th>\n      <th>Likes Received</th>\n      <th>Tweet Location</th>\n      <th>Tweet Language</th>\n      <th>...</th>\n      <th>Name</th>\n      <th>Username</th>\n      <th>User Bio</th>\n      <th>Verified or Non-Verified</th>\n      <th>Profile URL</th>\n      <th>Protected or Non-protected</th>\n      <th>User Followers</th>\n      <th>User Following</th>\n      <th>User Account Creation Date</th>\n      <th>Impressions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>\"1167429261210218497\"</td>\n      <td>https://twitter.com/animalhealthEU/status/1167...</td>\n      <td>30 Aug 2019 13:30:00</td>\n      <td>pets change lives amp become part families tha...</td>\n      <td>Tweet</td>\n      <td>Twitter Ads Composer</td>\n      <td>0</td>\n      <td>4</td>\n      <td>Brussels</td>\n      <td>English</td>\n      <td>...</td>\n      <td>AnimalhealthEurope</td>\n      <td>animalhealthEU</td>\n      <td>AnimalhealthEurope represents manufacturers of...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/animalhealthEU</td>\n      <td>Non-Protected</td>\n      <td>3697</td>\n      <td>542</td>\n      <td>17 Dec 2012 09:14:15</td>\n      <td>7394</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\"1167375334670557185\"</td>\n      <td>https://twitter.com/PennyBrohnUK/status/116737...</td>\n      <td>30 Aug 2019 09:55:43</td>\n      <td>another spot morethanmedicine bus bristol week...</td>\n      <td>Tweet</td>\n      <td>Twitter Web App</td>\n      <td>0</td>\n      <td>5</td>\n      <td>Pill, Bristol</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Penny Brohn UK</td>\n      <td>PennyBrohnUK</td>\n      <td>We help people live well with the impact of ca...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/PennyBrohnUK</td>\n      <td>Non-Protected</td>\n      <td>3227</td>\n      <td>1571</td>\n      <td>15 Sep 2010 09:44:02</td>\n      <td>6454</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"1167237977615097861\"</td>\n      <td>https://twitter.com/lordbyronaf/status/1167237...</td>\n      <td>30 Aug 2019 00:49:54</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>ReTweet</td>\n      <td>Twitter for Android</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Ohio, USA</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Lord ByronAF</td>\n      <td>lordbyronaf</td>\n      <td>It's easier to be who you are, than it is to b...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/lordbyronaf</td>\n      <td>Non-Protected</td>\n      <td>7808</td>\n      <td>8617</td>\n      <td>25 Jul 2012 15:43:47</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"1167236897078480898\"</td>\n      <td>https://twitter.com/CountessDavis/status/11672...</td>\n      <td>30 Aug 2019 00:45:37</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>ReTweet</td>\n      <td>Twitter for Android</td>\n      <td>0</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Lisa Countess davis</td>\n      <td>CountessDavis</td>\n      <td>I am named after @ElvisPresley daughter Lisa M...</td>\n      <td>Non-Verified</td>\n      <td>https://twitter.com/CountessDavis</td>\n      <td>Non-Protected</td>\n      <td>291</td>\n      <td>81</td>\n      <td>26 Jan 2017 18:21:42</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"1167228378191204353\"</td>\n      <td>https://twitter.com/Local12/status/11672283781...</td>\n      <td>30 Aug 2019 00:11:46</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>ReTweet</td>\n      <td>TweetDeck</td>\n      <td>0</td>\n      <td>0</td>\n      <td>Cincinnati, OH</td>\n      <td>English</td>\n      <td>...</td>\n      <td>Local 12/WKRC-TV</td>\n      <td>Local12</td>\n      <td>Local 12 is #Cincinnati's trusted source for b...</td>\n      <td>Verified</td>\n      <td>https://twitter.com/Local12</td>\n      <td>Non-Protected</td>\n      <td>198675</td>\n      <td>651</td>\n      <td>02 Sep 2008 20:09:44</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#corpus['Clean Tweets'] = normalize_corpus(corpus['Tweet Content'])\n",
    "corpus['Tweet Content'] = normalize_corpus(corpus['Tweet Content'])\n",
    "corpus.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Filtering only tweets (not re-tweets) use your class from part one of this exercise to build BOW and TF-IDF Vectorizer representations of the text; print your results. Don't over-think this, leverage what the author does in the text."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Model\n",
      "  (0, 2)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (3, 1)\t1\n",
      "  (4, 1)\t1\n",
      "  (5, 2)\t1\n",
      "  (6, 1)\t1\n",
      "  (7, 1)\t1\n",
      "  (8, 1)\t1\n",
      "  (9, 1)\t1\n",
      "  (10, 1)\t1\n",
      "  (11, 2)\t1\n",
      "  (12, 2)\t1\n",
      "  (13, 1)\t1\n",
      "  (14, 0)\t1\n",
      "  (15, 1)\t1\n",
      "  (16, 1)\t1\n",
      "  (17, 2)\t1\n",
      "  (18, 2)\t1\n",
      "  (19, 1)\t1\n",
      "  (20, 1)\t1\n",
      "  (21, 2)\t1\n",
      "  (22, 1)\t1\n",
      "  (23, 2)\t1\n",
      "  (24, 1)\t1\n",
      "  :\t:\n",
      "  (361, 2)\t1\n",
      "  (362, 1)\t1\n",
      "  (363, 2)\t1\n",
      "  (364, 2)\t1\n",
      "  (365, 1)\t1\n",
      "  (366, 2)\t1\n",
      "  (367, 1)\t1\n",
      "  (368, 1)\t1\n",
      "  (369, 1)\t1\n",
      "  (370, 1)\t1\n",
      "  (371, 0)\t1\n",
      "  (372, 1)\t1\n",
      "  (373, 1)\t1\n",
      "  (374, 1)\t1\n",
      "  (375, 1)\t1\n",
      "  (376, 1)\t1\n",
      "  (377, 1)\t1\n",
      "  (378, 2)\t1\n",
      "  (379, 1)\t1\n",
      "  (380, 2)\t1\n",
      "  (381, 1)\t1\n",
      "  (382, 2)\t1\n",
      "  (383, 1)\t1\n",
      "  (384, 1)\t1\n",
      "  (385, 2)\t1 \n",
      "\n",
      "[[0 0 1]\n",
      " [0 0 1]\n",
      " [0 1 0]\n",
      " ...\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]] \n",
      "\n",
      "     reply  retweet  tweet\n",
      "0        0        0      1\n",
      "1        0        0      1\n",
      "2        0        1      0\n",
      "3        0        1      0\n",
      "4        0        1      0\n",
      "..     ...      ...    ...\n",
      "381      0        1      0\n",
      "382      0        0      1\n",
      "383      0        1      0\n",
      "384      0        1      0\n",
      "385      0        0      1\n",
      "\n",
      "[386 rows x 3 columns] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [133], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\u001B[39;00m\n\u001B[0;32m     23\u001B[0m bv \u001B[38;5;241m=\u001B[39m CountVectorizer(ngram_range\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m2\u001B[39m))\n\u001B[1;32m---> 24\u001B[0m bv_matrix \u001B[38;5;241m=\u001B[39m \u001B[43mbv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTweet Type\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m bv_matrix \u001B[38;5;241m=\u001B[39m bv_matrix\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[0;32m     26\u001B[0m vocab \u001B[38;5;241m=\u001B[39m bv\u001B[38;5;241m.\u001B[39mget_feature_names_out()\n",
      "File \u001B[1;32m~\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1338\u001B[0m, in \u001B[0;36mCountVectorizer.fit_transform\u001B[1;34m(self, raw_documents, y)\u001B[0m\n\u001B[0;32m   1330\u001B[0m             warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m   1331\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUpper case characters found in\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1332\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m vocabulary while \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlowercase\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1333\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m is True. These entries will not\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1334\u001B[0m                 \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m be matched with any documents\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1335\u001B[0m             )\n\u001B[0;32m   1336\u001B[0m             \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[1;32m-> 1338\u001B[0m vocabulary, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_count_vocab\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfixed_vocabulary_\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbinary:\n\u001B[0;32m   1341\u001B[0m     X\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mfill(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[1;32m~\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1228\u001B[0m, in \u001B[0;36mCountVectorizer._count_vocab\u001B[1;34m(self, raw_documents, fixed_vocab)\u001B[0m\n\u001B[0;32m   1226\u001B[0m     vocabulary \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(vocabulary)\n\u001B[0;32m   1227\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m vocabulary:\n\u001B[1;32m-> 1228\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1229\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1230\u001B[0m         )\n\u001B[0;32m   1232\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m indptr[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39miinfo(np\u001B[38;5;241m.\u001B[39mint32)\u001B[38;5;241m.\u001B[39mmax:  \u001B[38;5;66;03m# = 2**31 - 1\u001B[39;00m\n\u001B[0;32m   1233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _IS_32BIT:\n",
      "\u001B[1;31mValueError\u001B[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "#BOW\n",
    "print('Bag of Words Model')\n",
    "# starting on page 208\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# get bag of words features in sparse format\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(corpus['Tweet Type'])\n",
    "# view non-zero feature positions in the sparse matrix\n",
    "print(cv_matrix, '\\n')\n",
    "\n",
    "# view dense representation\n",
    "# warning - might give a memory error if the data is too big\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "print(cv_matrix, '\\n')\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names_out()\n",
    "#show document feature vectors\n",
    "cv_df = pd.DataFrame(cv_matrix, columns=vocab)\n",
    "print(cv_df, '\\n')\n",
    "\n",
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(corpus['Tweet Type'])\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab = bv.get_feature_names_out()\n",
    "bv_df = pd.DataFrame(bv_matrix, columns=vocab)\n",
    "print(bv_df, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf transformer:\n",
      "     reply  retweet  tweet\n",
      "0      0.0      0.0    1.0\n",
      "1      0.0      0.0    1.0\n",
      "2      0.0      1.0    0.0\n",
      "3      0.0      1.0    0.0\n",
      "4      0.0      1.0    0.0\n",
      "..     ...      ...    ...\n",
      "381    0.0      1.0    0.0\n",
      "382    0.0      0.0    1.0\n",
      "383    0.0      1.0    0.0\n",
      "384    0.0      1.0    0.0\n",
      "385    0.0      0.0    1.0\n",
      "\n",
      "[386 rows x 3 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Tf-Idf Transformer\n",
    "print('tfidf transformer:')\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tt = TfidfTransformer(norm = 'l2', use_idf=True)\n",
    "tt_matrix = tt.fit_transform(cv_matrix)\n",
    "tt_matrix = tt_matrix.toarray()\n",
    "vocab = cv.get_feature_names_out()\n",
    "print(pd.DataFrame(np.round(tt_matrix, 2), columns=vocab), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Find one or more documents (each tweet is a document) that are similar to each other using Cosine Similarity; print your results. (NOTE: the lower the Cosine Similarity, the more likely the documents are similar.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf vectorizer:\n",
      "     ability  academic  acep  acepnow  acoeprso  across  act  activity  \\\n",
      "0        0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "1        0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "2        0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "3        0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "4        0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "..       ...       ...   ...      ...       ...     ...  ...       ...   \n",
      "381      0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "382      0.0      0.23   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "383      0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "384      0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "385      0.0      0.00   0.0      0.0       0.0     0.0  0.0       0.0   \n",
      "\n",
      "     address  advice  ...  yet  youll  young  youre  zoetis  zones  zoonosen  \\\n",
      "0        0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "1        0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "2        0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "3        0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "4        0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "..       ...     ...  ...  ...    ...    ...    ...     ...    ...       ...   \n",
      "381      0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "382      0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "383      0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "384      0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "385      0.0     0.0  ...  0.0    0.0    0.0    0.0     0.0    0.0       0.0   \n",
      "\n",
      "     zoonoses   zu  zwierzt  \n",
      "0         0.0  0.0      0.0  \n",
      "1         0.0  0.0      0.0  \n",
      "2         0.0  0.0      0.0  \n",
      "3         0.0  0.0      0.0  \n",
      "4         0.0  0.0      0.0  \n",
      "..        ...  ...      ...  \n",
      "381       0.0  0.0      0.0  \n",
      "382       0.0  0.0      0.0  \n",
      "383       0.0  0.0      0.0  \n",
      "384       0.0  0.0      0.0  \n",
      "385       0.0  0.0      0.0  \n",
      "\n",
      "[386 rows x 1062 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('tfidf vectorizer:')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., norm='l2', use_idf=True, smooth_idf=True)\n",
    "tv_matrix = tv.fit_transform(corpus['Tweet Content'])\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "# this part is not in the book - save the tv_matrix for use later on\n",
    "import os\n",
    "np.save('tv_matrix.npy', tv_matrix)\n",
    "\n",
    "vocab = tv.get_feature_names_out()\n",
    "print(pd.DataFrame(np.round(tv_matrix, 2), columns=vocab), '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix DF:\n",
      "           0         1         2         3         4         5         6    \\\n",
      "0    1.000000  0.002240  0.003851  0.003851  0.003851  0.003851  0.002302   \n",
      "1    0.002240  1.000000  0.004446  0.004446  0.004446  0.004446  0.002658   \n",
      "2    0.003851  0.004446  1.000000  1.000000  1.000000  1.000000  0.004569   \n",
      "3    0.003851  0.004446  1.000000  1.000000  1.000000  1.000000  0.004569   \n",
      "4    0.003851  0.004446  1.000000  1.000000  1.000000  1.000000  0.004569   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "381  0.090952  0.003131  0.005382  0.005382  0.005382  0.005382  0.003217   \n",
      "382  0.001977  0.002283  0.076390  0.076390  0.076390  0.076390  0.087237   \n",
      "383  0.090952  0.003131  0.005382  0.005382  0.005382  0.005382  0.003217   \n",
      "384  0.090952  0.003131  0.005382  0.005382  0.005382  0.005382  0.003217   \n",
      "385  0.090952  0.003131  0.005382  0.005382  0.005382  0.005382  0.003217   \n",
      "\n",
      "          7         8         9    ...       376       377       378  \\\n",
      "0    0.002302  0.002302  0.002302  ...  0.002491  0.001977  0.002491   \n",
      "1    0.002658  0.002658  0.002658  ...  0.002876  0.002283  0.002876   \n",
      "2    0.004569  0.004569  0.004569  ...  0.004944  0.076390  0.004944   \n",
      "3    0.004569  0.004569  0.004569  ...  0.004944  0.076390  0.004944   \n",
      "4    0.004569  0.004569  0.004569  ...  0.004944  0.076390  0.004944   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "381  0.003217  0.003217  0.003217  ...  0.003481  0.002763  0.003481   \n",
      "382  0.087237  0.087237  0.087237  ...  0.170560  1.000000  0.170560   \n",
      "383  0.003217  0.003217  0.003217  ...  0.003481  0.002763  0.003481   \n",
      "384  0.003217  0.003217  0.003217  ...  0.003481  0.002763  0.003481   \n",
      "385  0.003217  0.003217  0.003217  ...  0.003481  0.002763  0.003481   \n",
      "\n",
      "          379       380       381       382       383       384       385  \n",
      "0    0.001977  0.028301  0.090952  0.001977  0.090952  0.090952  0.090952  \n",
      "1    0.002283  0.002062  0.003131  0.002283  0.003131  0.003131  0.003131  \n",
      "2    0.076390  0.003544  0.005382  0.076390  0.005382  0.005382  0.005382  \n",
      "3    0.076390  0.003544  0.005382  0.076390  0.005382  0.005382  0.005382  \n",
      "4    0.076390  0.003544  0.005382  0.076390  0.005382  0.005382  0.005382  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "381  0.002763  0.019552  1.000000  0.002763  1.000000  1.000000  1.000000  \n",
      "382  1.000000  0.001820  0.002763  1.000000  0.002763  0.002763  0.002763  \n",
      "383  0.002763  0.019552  1.000000  0.002763  1.000000  1.000000  1.000000  \n",
      "384  0.002763  0.019552  1.000000  0.002763  1.000000  1.000000  1.000000  \n",
      "385  0.002763  0.019552  1.000000  0.002763  1.000000  1.000000  1.000000  \n",
      "\n",
      "[386 rows x 386 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the tv_matrix save in the last file\n",
    "tv_matrix = np.load('tv_matrix.npy')\n",
    "\n",
    "# Document Similarity - staring on page 221\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "print('Similarity matrix DF:\\n', similarity_df, '\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math  import sqrt\n",
    "\n",
    "def word2vec(word):\n",
    "    # Count the number of characters in each word.\n",
    "    count_characters = Counter(word)\n",
    "    # Gets the set of characters and calculates the \"length\" of the vector.\n",
    "    set_characters = set(count_characters)\n",
    "    length = sqrt(sum(c*c for c in count_characters.values()))\n",
    "    return count_characters, set_characters, length, word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [],
   "source": [
    "def cosine_similarity(vector1, vector2, ndigits):\n",
    "\n",
    "    # Get the common characters between the two character sets\n",
    "    common_characters = vector1[1].intersection(vector2[1])\n",
    "    # Sum of the product of each intersection character.\n",
    "    product_summation = sum(vector1[0][character] * vector2[0]                  [character] for character in common_characters)\n",
    "    # Gets the length of each vector from the word2vec output.\n",
    "    length = vector1[2] * vector2[2]\n",
    "    # Calculates cosine similarity and rounds the value to ndigits decimal places.\n",
    "    if length == 0:\n",
    "        # Set value to 0 if word is empty.\n",
    "        similarity = 0\n",
    "    else:\n",
    "        similarity = round(product_summation/length, ndigits)\n",
    "    return similarity"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "ndigits = (len(corpus['Tweet Content']))\n",
    "similarity_threshold = 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "def find_similar(full_names_list, similarity_threshold, ndigits):\n",
    "    # Initiate an empty list to store results.\n",
    "    results_list = []\n",
    "    # Apply word2vec function to each name and store them in a list.\n",
    "    vector_list = [word2vec(str(i)) for i in full_names_list]\n",
    "    # Two loops to compare each vector with another vector only once.\n",
    "    for i in range(len(vector_list)):\n",
    "        # Get first vector\n",
    "        vector1 = vector_list[i]\n",
    "        for j in range(i+1, len(vector_list)):\n",
    "            # Get the next vector\n",
    "            vector2 = vector_list[j]\n",
    "            # Calculate cosine similarity\n",
    "            similarity_score = cosine_similarity(vector1, vector2, ndigits)\n",
    "            # Append to results list if similarity score is between 1 and the threshold.\n",
    "            # Note that scores of 1 can be ignored here if we want to exclude people with the same name.\n",
    "            if 1 >= similarity_score >= similarity_threshold:\n",
    "                results_list.append([vector1[3], vector2[3], similarity_score])\n",
    "            else:\n",
    "                pass\n",
    "    # Convert list to dataframe.\n",
    "    results_df = pd.DataFrame(results_list)\n",
    "    if len(results_df) != 0:\n",
    "        results_df.columns = ['Original_tweet', 'Compared_Tweet', 'Similarity_score']\n",
    "    else:\n",
    "    # Can add error here if there's no results to return if desired.\n",
    "        pass\n",
    "    return results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "                                          Original_tweet  \\\n0      pets change lives amp become part families tha...   \n1      pets change lives amp become part families tha...   \n2      pets change lives amp become part families tha...   \n3      pets change lives amp become part families tha...   \n4      pets change lives amp become part families tha...   \n...                                                  ...   \n74176  great weekend rebellion back month tipsfornewd...   \n74177  great weekend rebellion back month tipsfornewd...   \n74178  morethanmedicine mean protecting animalhealth ...   \n74179  morethanmedicine mean protecting animalhealth ...   \n74180  morethanmedicine mean protecting animalhealth ...   \n\n                                          Compared_Tweet  Similarity_score  \n0      another spot morethanmedicine bus bristol week...          0.928081  \n1      great team healthsourceoh local morethanmedici...          0.914231  \n2      great team healthsourceoh local morethanmedici...          0.914231  \n3      great team healthsourceoh local morethanmedici...          0.914231  \n4      great team healthsourceoh local morethanmedici...          0.914231  \n...                                                  ...               ...  \n74176  morethanmedicine mean protecting animalhealth ...          0.933120  \n74177  morethanmedicine mean protecting animalhealth ...          0.933120  \n74178  morethanmedicine mean protecting animalhealth ...          1.000000  \n74179  morethanmedicine mean protecting animalhealth ...          1.000000  \n74180  morethanmedicine mean protecting animalhealth ...          1.000000  \n\n[74181 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Original_tweet</th>\n      <th>Compared_Tweet</th>\n      <th>Similarity_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pets change lives amp become part families tha...</td>\n      <td>another spot morethanmedicine bus bristol week...</td>\n      <td>0.928081</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>pets change lives amp become part families tha...</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>0.914231</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pets change lives amp become part families tha...</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>0.914231</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>pets change lives amp become part families tha...</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>0.914231</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>pets change lives amp become part families tha...</td>\n      <td>great team healthsourceoh local morethanmedici...</td>\n      <td>0.914231</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>74176</th>\n      <td>great weekend rebellion back month tipsfornewd...</td>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>0.933120</td>\n    </tr>\n    <tr>\n      <th>74177</th>\n      <td>great weekend rebellion back month tipsfornewd...</td>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>0.933120</td>\n    </tr>\n    <tr>\n      <th>74178</th>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>74179</th>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>74180</th>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>morethanmedicine mean protecting animalhealth ...</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>74181 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar(corpus['Tweet Content'], similarity_threshold, ndigits)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}