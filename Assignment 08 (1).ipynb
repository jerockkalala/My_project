{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Interactive Querying with Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assignment 8\n",
    "\n",
    "In this assignment, you will create a small SQL-based data warehouse using [Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html). You will then run basic SQL queries on the dataset. \n",
    "\n",
    "For this assignment, we will use a dataset derived from the [official Stardew Valley wiki](https://stardewvalleywiki.com/Stardew_Valley_Wiki) whose content is available under the [Creative Commons Attribution-NonCommercial-ShareAlike]( https://creativecommons.org/licenses/by-nc-sa/3.0/) license. \n",
    "\n",
    "As a first step, we load the CSV files into Pandas dataframes.  In a later stage, you will convert these to run as Spark dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "base_github_repo_url = 'https://raw.githubusercontent.com/bellevue-university/dsc400/main'\n",
    "family_csv_url = base_github_repo_url + '/data/stardew/family.csv'\n",
    "friends_csv_url = base_github_repo_url + '/data/stardew/friends.csv'\n",
    "gifts_csv_url = base_github_repo_url + '/data/stardew/gifts.csv'\n",
    "villagers_csv_url = base_github_repo_url + '/data/stardew/villagers.csv'\n",
    "\n",
    "pd_df_family = pd.read_csv(family_csv_url, index_col='id')\n",
    "pd_df_gifts = pd.read_csv(gifts_csv_url, index_col='id')\n",
    "pd_df_friends = pd.read_csv(friends_csv_url, index_col='id')\n",
    "pd_df_villagers = pd.read_csv(villagers_csv_url, index_col='id')\n",
    "\n",
    "pd_df_villagers['birthday'] = pd_df_villagers['birthday'].replace(np.nan, 'Unknown')\n",
    "pd_df_villagers['address'] = pd_df_villagers['address'].replace(np.nan, 'Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following code removes the `spark-warehouse` directory if it exists. This is done to prevent any issues associated with a previously created `spark-warehouse` folder. Run this code if you experience issues creating temporary tables in Spark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os \n",
    "import shutil\n",
    "\n",
    "current_working_dir = Path(os.getcwd())\n",
    "spark_warehouse_dir = current_working_dir.joinpath('spark-warehouse')\n",
    "if spark_warehouse_dir.exists():\n",
    "    shutil.rmtree(spark_warehouse_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 8.1\n",
    "\n",
    "In the first part of the assignment, you will create Spark dataframes from the existing Pandas dataframes. Once you create the Spark dataframes, print the schema using `printSchema` and show the dataframe using `show`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/12 14:45:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/02/12 14:45:28 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DSC 400 Assignment 8\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark_context = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The following is fully implemented code that converts the `pd_df_family` dataframe into a Spark dataframe, prints the schema, and shows the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:474: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n",
      "/usr/local/spark/python/pyspark/sql/pandas/conversion.py:486: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for column, series in pdf.iteritems():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- villager_id: string (nullable = true)\n",
      " |-- family_member_id: string (nullable = true)\n",
      " |-- relationship: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------+\n",
      "|villager_id|family_member_id|relationship|\n",
      "+-----------+----------------+------------+\n",
      "|    Abigail|          Pierre|      Father|\n",
      "|    Abigail|        Caroline|      Mother|\n",
      "|       Alex|          Evelyn| Grandmother|\n",
      "|       Alex|          George| Grandfather|\n",
      "|   Caroline|          Pierre|     Husband|\n",
      "|   Caroline|         Abigail|    Daughter|\n",
      "|  Demetrius|           Robin|        Wife|\n",
      "|  Demetrius|            Maru|    Daughter|\n",
      "|  Demetrius|       Sebastian|    Step-son|\n",
      "|      Emily|           Haley|      Sister|\n",
      "|     Evelyn|          George|     Husband|\n",
      "|     Evelyn|            Alex|    Grandson|\n",
      "|     George|          Evelyn|        Wife|\n",
      "|     George|            Alex|    Grandson|\n",
      "|      Haley|           Emily|      Sister|\n",
      "|        Jas|          Marnie|        Aunt|\n",
      "|        Jas|           Shane|   Godfather|\n",
      "|       Jodi|            Kent|     Husband|\n",
      "|       Jodi|             Sam|         Son|\n",
      "|       Jodi|         Vincent|         Son|\n",
      "+-----------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_family = spark.createDataFrame(pd_df_family)\n",
    "df_family.printSchema()\n",
    "df_family.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Repeat the process shown above for the remaining dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gift_id: string (nullable = true)\n",
      " |-- villager_id: string (nullable = true)\n",
      "\n",
      "+------------------+-----------+\n",
      "|           gift_id|villager_id|\n",
      "+------------------+-----------+\n",
      "|          Amethyst|    Abigail|\n",
      "|    Banana Pudding|    Abigail|\n",
      "|Blackberry Cobbler|    Abigail|\n",
      "|    Chocolate Cake|    Abigail|\n",
      "|        Pufferfish|    Abigail|\n",
      "|           Pumpkin|    Abigail|\n",
      "|         Spicy Eel|    Abigail|\n",
      "|Complete Breakfast|       Alex|\n",
      "|     Salmon Dinner|       Alex|\n",
      "|         Fish Taco|   Caroline|\n",
      "|         Green Tea|   Caroline|\n",
      "|    Summer Spangle|   Caroline|\n",
      "|    Tropical Curry|   Caroline|\n",
      "|          Amethyst|      Clint|\n",
      "|        Aquamarine|      Clint|\n",
      "|     Artichoke Dip|      Clint|\n",
      "|           Emerald|      Clint|\n",
      "|Fiddlehead Risotto|      Clint|\n",
      "|          Gold Bar|      Clint|\n",
      "|       Iridium Bar|      Clint|\n",
      "+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a PySpark dataframe `df_gifts` from `pd_df_gifts`\n",
    "\n",
    "# TODO: Print the schema and show the dataframe\n",
    "df_gifts = spark.createDataFrame(pd_df_gifts)\n",
    "df_gifts.printSchema()\n",
    "df_gifts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- villager_id: string (nullable = true)\n",
      " |-- friend_id: string (nullable = true)\n",
      "\n",
      "+-----------+---------+\n",
      "|villager_id|friend_id|\n",
      "+-----------+---------+\n",
      "|    Abigail|      Sam|\n",
      "|    Abigail|Sebastian|\n",
      "|       Alex|    Haley|\n",
      "|   Caroline|     Jodi|\n",
      "|      Clint|    Emily|\n",
      "|    Elliott|     Leah|\n",
      "|    Elliott|    Willy|\n",
      "|      Emily|    Sandy|\n",
      "|        Gil|   Marlon|\n",
      "|        Gus|      Pam|\n",
      "|      Haley|     Alex|\n",
      "|     Harvey|     Maru|\n",
      "|        Jas|      Leo|\n",
      "|        Jas|  Vincent|\n",
      "|       Jodi| Caroline|\n",
      "|       Leah|  Elliott|\n",
      "|        Leo|      Jas|\n",
      "|        Leo|    Linus|\n",
      "|        Leo|  Vincent|\n",
      "|      Lewis|   Marnie|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a PySpark dataframe `df_friends` from `pd_df_friends`\n",
    "# TODO: Print the schema and show the dataframe\n",
    "df_friends = spark.createDataFrame(pd_df_friends)\n",
    "df_friends.printSchema()\n",
    "df_friends.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We need to create an explicit schema for the villager dataframe as Spark has difficulty infering this schema from the Pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StringType, BooleanType, StructField\n",
    "\n",
    "villager_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"birthday\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"is_marriable\", BooleanType(), True),\n",
    "    StructField(\"img_url\", StringType(), True),\n",
    "])\n",
    "\n",
    "df_villagers = spark.createDataFrame(pd_df_villagers, villager_schema)\n",
    "\n",
    "# TODO: Print the schema and show the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 8.2\n",
    "\n",
    "Now that we have loaded the dataframes, we will use the dataframes to create a temporary SQL-based data warehouse. In a production environment, we could persist these tables for later use. \n",
    "\n",
    "Register each of the dataframes as a Spark [Global Tempory View](http://spark.apache.org/docs/latest/sql-getting-started.html#global-temporary-view) using the view names, *family*, *friends*, *gifts*, and *villagers* for the dataframes *df_family*, *df_friends*, *df_gifts*, and *df_villagers* respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create a temporary `family` view using the `df_family` dataframe\n",
    "df_family.registerTempTable(\"family\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create a temporary `friends` view using the `df_friends` dataframe\n",
    "df_friends.registerTempTable(\"friends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create a temporary `gifts` view using the `df_gifts` dataframe\n",
    "df_gifts.registerTempTable(\"gifts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Create a temporary `villagers` view using the `df_villagers` dataframe\n",
    "df_villagers.registerTempTable(\"villagers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Verify that the views exist by using the following SQL queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------+\n",
      "|villager_id|family_member_id|relationship|\n",
      "+-----------+----------------+------------+\n",
      "|    Abigail|          Pierre|      Father|\n",
      "|    Abigail|        Caroline|      Mother|\n",
      "|       Alex|          Evelyn| Grandmother|\n",
      "|       Alex|          George| Grandfather|\n",
      "|   Caroline|          Pierre|     Husband|\n",
      "|   Caroline|         Abigail|    Daughter|\n",
      "|  Demetrius|           Robin|        Wife|\n",
      "|  Demetrius|            Maru|    Daughter|\n",
      "|  Demetrius|       Sebastian|    Step-son|\n",
      "|      Emily|           Haley|      Sister|\n",
      "|     Evelyn|          George|     Husband|\n",
      "|     Evelyn|            Alex|    Grandson|\n",
      "|     George|          Evelyn|        Wife|\n",
      "|     George|            Alex|    Grandson|\n",
      "|      Haley|           Emily|      Sister|\n",
      "|        Jas|          Marnie|        Aunt|\n",
      "|        Jas|           Shane|   Godfather|\n",
      "|       Jodi|            Kent|     Husband|\n",
      "|       Jodi|             Sam|         Son|\n",
      "|       Jodi|         Vincent|         Son|\n",
      "+-----------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This should output the first 20 rows of the family table\n",
    "spark.sql(\"SELECT * FROM family\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|villager_id|friend_id|\n",
      "+-----------+---------+\n",
      "|    Abigail|      Sam|\n",
      "|    Abigail|Sebastian|\n",
      "|       Alex|    Haley|\n",
      "|   Caroline|     Jodi|\n",
      "|      Clint|    Emily|\n",
      "|    Elliott|     Leah|\n",
      "|    Elliott|    Willy|\n",
      "|      Emily|    Sandy|\n",
      "|        Gil|   Marlon|\n",
      "|        Gus|      Pam|\n",
      "|      Haley|     Alex|\n",
      "|     Harvey|     Maru|\n",
      "|        Jas|      Leo|\n",
      "|        Jas|  Vincent|\n",
      "|       Jodi| Caroline|\n",
      "|       Leah|  Elliott|\n",
      "|        Leo|      Jas|\n",
      "|        Leo|    Linus|\n",
      "|        Leo|  Vincent|\n",
      "|      Lewis|   Marnie|\n",
      "+-----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This should output the first 20 rows of the friends table\n",
    "spark.sql(\"SELECT * FROM friends\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|           gift_id|villager_id|\n",
      "+------------------+-----------+\n",
      "|          Amethyst|    Abigail|\n",
      "|    Banana Pudding|    Abigail|\n",
      "|Blackberry Cobbler|    Abigail|\n",
      "|    Chocolate Cake|    Abigail|\n",
      "|        Pufferfish|    Abigail|\n",
      "|           Pumpkin|    Abigail|\n",
      "|         Spicy Eel|    Abigail|\n",
      "|Complete Breakfast|       Alex|\n",
      "|     Salmon Dinner|       Alex|\n",
      "|         Fish Taco|   Caroline|\n",
      "|         Green Tea|   Caroline|\n",
      "|    Summer Spangle|   Caroline|\n",
      "|    Tropical Curry|   Caroline|\n",
      "|          Amethyst|      Clint|\n",
      "|        Aquamarine|      Clint|\n",
      "|     Artichoke Dip|      Clint|\n",
      "|           Emerald|      Clint|\n",
      "|Fiddlehead Risotto|      Clint|\n",
      "|          Gold Bar|      Clint|\n",
      "|       Iridium Bar|      Clint|\n",
      "+------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This should output the first 20 rows of the gifts table\n",
    "spark.sql(\"SELECT * FROM gifts\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+------------+--------------------+\n",
      "|     name| birthday|             address|is_marriable|             img_url|\n",
      "+---------+---------+--------------------+------------+--------------------+\n",
      "|  Abigail|  Fall 13|Pierre's General ...|        true|https://stardewva...|\n",
      "|     Alex|Summer 13|        1 River Road|        true|https://stardewva...|\n",
      "|   Birdie|  Unknown|  Hut on Island West|       false|https://stardewva...|\n",
      "|  Bouncer|  Unknown|               Oasis|       false|https://stardewva...|\n",
      "| Caroline| Winter 7|Pierre's General ...|       false|https://stardewva...|\n",
      "|    Clint|Winter 26|          Blacksmith|       false|https://stardewva...|\n",
      "|Demetrius|Summer 19|    24 Mountain Road|       false|https://stardewva...|\n",
      "|    Dwarf|Summer 22|        Eastern Cave|       false|https://stardewva...|\n",
      "|  Elliott|   Fall 5|     Elliott's Cabin|        true|https://stardewva...|\n",
      "|    Emily|Spring 27|       2 Willow Lane|        true|https://stardewva...|\n",
      "|   Evelyn|Winter 20|        1 River Road|       false|https://stardewva...|\n",
      "|   George|  Fall 24|        1 River Road|       false|https://stardewva...|\n",
      "|      Gil|  Unknown|  Adventurer's Guild|       false|https://stardewva...|\n",
      "| Governor|  Unknown|             Unknown|       false|https://stardewva...|\n",
      "|  Grandpa|  Unknown|           Afterlife|       false|https://stardewva...|\n",
      "|  Gunther|  Unknown|              Museum|       false|https://stardewva...|\n",
      "|      Gus| Summer 8| The Stardrop Saloon|       false|https://stardewva...|\n",
      "|    Haley|Spring 14|       2 Willow Lane|        true|https://stardewva...|\n",
      "|   Harvey|Winter 14|      Medical Clinic|        true|https://stardewva...|\n",
      "| Henchman|  Unknown|             Unknown|       false|https://stardewva...|\n",
      "+---------+---------+--------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # This should output the first 20 rows of the villagers table\n",
    "spark.sql(\"SELECT * FROM villagers\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 8.3\n",
    "\n",
    "In the final part of the assignment, you will run some basic SQL queries. [Spark's SQL reference guide](http://spark.apache.org/docs/latest/sql-ref.html) and [Spark's SQL getting started guide](http://spark.apache.org/docs/latest/sql-getting-started.html) will help complete these queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 8.3.a\n",
    "\n",
    "Using a `SELECT` statement and `WHERE` clause, run a query that returns all Sebastian's friends. Sebastian's `villager_id` is Sebastian. Select only the `friend_id` column in the results to be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|friend_id|\n",
      "+---------+\n",
      "|  Abigail|\n",
      "|      Sam|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run SQL query to return a list of Sebastian's friends. \n",
    "result = spark.sql(\"SELECT friend_id FROM friends WHERE villager_id = 'Sebastian'\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Assignment 8.3.b\n",
    "\n",
    "Group the `friends` table by `villager_id` and perform a count of number of friends for each villager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:>                                                         (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+\n",
      "|friend_id|cnt|\n",
      "+---------+---+\n",
      "|     Jodi|  1|\n",
      "|      Sam|  3|\n",
      "|Sebastian|  2|\n",
      "|    Haley|  1|\n",
      "|    Sandy|  1|\n",
      "|    Willy|  1|\n",
      "|    Emily|  2|\n",
      "|     Leah|  1|\n",
      "|     Alex|  1|\n",
      "|     Maru|  2|\n",
      "|      Pam|  1|\n",
      "|   Marlon|  1|\n",
      "|    Linus|  2|\n",
      "|  Elliott|  2|\n",
      "|   Marnie|  1|\n",
      "|      Leo|  3|\n",
      "|      Jas|  2|\n",
      "|  Vincent|  2|\n",
      "| Caroline|  1|\n",
      "|   Wizard|  1|\n",
      "+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# TODO: Group the `friends` table by `villager_id` and perform a count of number of friends for each villager. \n",
    "#result = spark.sql(\"SELECT villager_id FROM friends\")\n",
    "result = spark.sql(\"SELECT friend_id, COUNT(*) AS cnt FROM friends GROUP BY friend_id\")\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}