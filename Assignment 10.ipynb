{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Classification in PySpark and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Assignment 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DSC 400 Assignment 10\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# TODO: Change these to point to a version on your local path\n",
    "sample_libsvm_data_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 10.1\n",
    "\n",
    "Run the PySpark version of the binomial logistic regression example found in [Apache Spark's binomial logistic regression documentation](https://spark.apache.org/docs/latest/ml-classification-regression.html#binomial-logistic-regression). You can also find the code in [Apache Spark's Github repository](https://github.com/apache/spark/tree/master/examples/src/main/python/mllib). \n",
    "\n",
    "The example references a `sample_libsvm_data.txt\n",
    "` file. You can find the file at https://raw.githubusercontent.com/apache/spark/master/data/mllib/sample_libsvm_data.txt\n",
    ". Put this file in your working path and change the following code to point to your local version of the file. \n",
    "\n",
    "```\n",
    "training = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "```\n",
    "\n",
    "Provide a summary of the training results using [Apache Spark's BinaryLogisticRegressionTrainingSummary class](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.ml.classification.BinaryLogisticRegressionTrainingSummary.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Load training data\n",
    "training = spark.read.format(\"libsvm\").load(\"E:\\\\Bellevue\\\\Winter_2022\\\\DSC 400 Big Data, Technology, and Algo\\\\Week_1\\\\sample_libsvm_data.txt\")\n",
    "\n",
    "# TODO: Implement the remainder of the code from the binomial logistic regression example example\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# We can also use the multinomial family for binary classification\n",
    "mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "mlrModel = mlr.fit(training)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Assignment 10.2\n",
    "\n",
    "Follow the instructions on [Kera's Structured data classification from scratch example](https://keras.io/examples/structured_data/structured_data_classification_from_scratch/) to perform binary classification using deep learning. You can find the [complete code for this example on Kera's Github repository](https://github.com/keras-team/keras-io/blob/master/examples/structured_data/structured_data_classification_from_scratch.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)\n",
    "\n",
    "# TODO: Complete the remainder of the example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
      "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
      "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
      "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
      "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
      "\n",
      "   ca        thal  target  \n",
      "0   0       fixed       0  \n",
      "1   3      normal       1  \n",
      "2   2  reversible       0  \n",
      "3   0      normal       0  \n",
      "4   0      normal       0  \n"
     ]
    },
    {
     "data": {
      "text/plain": "(303, 14)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe.head())\n",
    "dataframe.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's split the data into a training and validation set:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's generate tf.data.Dataset objects for each dataframe:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=61>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=130>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=330>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=169>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=0.0>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=1>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'normal'>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's batch the datasets:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature preprocessing with Keras layers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build a model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")\n",
    "\n",
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Let's visualize our connectivity graph:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Train the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 2s 50ms/step - loss: 0.7737 - accuracy: 0.5207 - val_loss: 0.7104 - val_accuracy: 0.6230\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.7490 - accuracy: 0.5992 - val_loss: 0.6469 - val_accuracy: 0.7049\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6628 - accuracy: 0.6364 - val_loss: 0.5964 - val_accuracy: 0.7541\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.6700 - accuracy: 0.6281 - val_loss: 0.5530 - val_accuracy: 0.7705\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5510 - accuracy: 0.7231 - val_loss: 0.5169 - val_accuracy: 0.7705\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5593 - accuracy: 0.7149 - val_loss: 0.4882 - val_accuracy: 0.7705\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7727 - val_loss: 0.4652 - val_accuracy: 0.7705\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.5337 - accuracy: 0.7066 - val_loss: 0.4449 - val_accuracy: 0.7869\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4998 - accuracy: 0.7686 - val_loss: 0.4284 - val_accuracy: 0.7541\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.7603 - val_loss: 0.4154 - val_accuracy: 0.7377\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7934 - val_loss: 0.4054 - val_accuracy: 0.7377\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4647 - accuracy: 0.7521 - val_loss: 0.3968 - val_accuracy: 0.7705\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7810 - val_loss: 0.3900 - val_accuracy: 0.8033\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7686 - val_loss: 0.3835 - val_accuracy: 0.8197\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8140 - val_loss: 0.3788 - val_accuracy: 0.8197\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3898 - accuracy: 0.8223 - val_loss: 0.3752 - val_accuracy: 0.8197\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8388 - val_loss: 0.3717 - val_accuracy: 0.8197\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8223 - val_loss: 0.3688 - val_accuracy: 0.8197\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8140 - val_loss: 0.3667 - val_accuracy: 0.8197\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8182 - val_loss: 0.3656 - val_accuracy: 0.8525\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3759 - accuracy: 0.8182 - val_loss: 0.3648 - val_accuracy: 0.8525\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3496 - accuracy: 0.8512 - val_loss: 0.3641 - val_accuracy: 0.8525\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3324 - accuracy: 0.8388 - val_loss: 0.3641 - val_accuracy: 0.8525\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8554 - val_loss: 0.3646 - val_accuracy: 0.8525\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3351 - accuracy: 0.8678 - val_loss: 0.3648 - val_accuracy: 0.8525\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3485 - accuracy: 0.8347 - val_loss: 0.3642 - val_accuracy: 0.8525\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3262 - accuracy: 0.8554 - val_loss: 0.3645 - val_accuracy: 0.8525\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3007 - accuracy: 0.8719 - val_loss: 0.3647 - val_accuracy: 0.8525\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3339 - accuracy: 0.8595 - val_loss: 0.3648 - val_accuracy: 0.8525\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3140 - accuracy: 0.8636 - val_loss: 0.3649 - val_accuracy: 0.8525\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3513 - accuracy: 0.8471 - val_loss: 0.3652 - val_accuracy: 0.8525\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3173 - accuracy: 0.8843 - val_loss: 0.3664 - val_accuracy: 0.8361\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3364 - accuracy: 0.8636 - val_loss: 0.3675 - val_accuracy: 0.8525\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2943 - accuracy: 0.8843 - val_loss: 0.3689 - val_accuracy: 0.8525\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3093 - accuracy: 0.8636 - val_loss: 0.3705 - val_accuracy: 0.8361\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3031 - accuracy: 0.8802 - val_loss: 0.3714 - val_accuracy: 0.8361\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2938 - accuracy: 0.8595 - val_loss: 0.3722 - val_accuracy: 0.8197\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2838 - accuracy: 0.8802 - val_loss: 0.3731 - val_accuracy: 0.8361\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3038 - accuracy: 0.8512 - val_loss: 0.3742 - val_accuracy: 0.8361\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.3056 - accuracy: 0.8802 - val_loss: 0.3756 - val_accuracy: 0.8361\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2673 - accuracy: 0.8967 - val_loss: 0.3772 - val_accuracy: 0.8197\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2785 - accuracy: 0.8843 - val_loss: 0.3782 - val_accuracy: 0.8197\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2975 - accuracy: 0.8678 - val_loss: 0.3779 - val_accuracy: 0.8197\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2650 - accuracy: 0.8967 - val_loss: 0.3782 - val_accuracy: 0.8197\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2709 - accuracy: 0.8843 - val_loss: 0.3788 - val_accuracy: 0.8197\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2976 - accuracy: 0.8595 - val_loss: 0.3784 - val_accuracy: 0.8197\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2803 - accuracy: 0.9008 - val_loss: 0.3780 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2861 - accuracy: 0.8760 - val_loss: 0.3784 - val_accuracy: 0.8197\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2801 - accuracy: 0.8636 - val_loss: 0.3786 - val_accuracy: 0.8197\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.2634 - accuracy: 0.8719 - val_loss: 0.3788 - val_accuracy: 0.8197\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1ba98d05d50>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}